---
title: Sentiment Lexicon Translation from English to Hausa
date: 2021-01-17
draft: true
authors:
- admin
tags:
- corpus
featured: false
# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
image:
  placement: 3gi
  caption: 'Why Blog'
  focal_point: "Smart"
  preview_only: true
---





```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hausa Sentiment Lexicon Generation

-- What is entiment lexicon
-- why them? what are use for?
In this maiden blog post, we will translate sentiment lexicon from the most widely used English lexicon to Hausa. The translated lexicon will then be use to perform sentiment analyis in using Hausa text.



## R Markdown

```{r}
library(googleLanguageR)
gl_auth("hausalex_credential.json")

```

```{r}
library(tidytext)
library(tidyverse)
library(textdata)
```


```{r}
bin <- get_sentiments("bing") 

bin_pos <- bin %>% filter(sentiment == "positive")

bin_neg <- bin %>% filter(sentiment == "negative")

```



```{r}

bin_pos_words <- bin_pos %>% 
              pull("word")

bin_neg_words <- bin_neg %>% 
              pull("word") 

```


```{r}
length(bin_pos_words)
length(bin_neg_words)
```


# Yoruba
```{r}
bin_positive_tranlated_yoruba <- gl_translate(bin_pos_words, format = 'text', source = 'en', target = "yo", model = "nmt")
```



```{r}


write.csv(bin_positive_tranlated_yoruba, "~/Documents/R Directory/HausaLex/bin_positive_tranlated_Yoruba.csv")

```


```{r}
bin_negative_tranlated_yoruba <- gl_translate(bin_neg_words, format = 'text', source = 'en', target = "yo", model = "nmt")
```

```{r}
write.csv(bin_negative_tranlated_yoruba, "~/Documents/R Directory/HausaLex/bin_negative_tranlated_yoruba.csv")
```


# Remove 0s
```{r}
affin <- lexicon_afinn()

affin_neu  <- affin  %>% filter(value == 0)
affin_pos <-  affin %>% filter(value >0) 
affin_neg <- affin %>% filter(value < 0) 

```



```{r}
affin_pos_words <-  affin_pos %>% pull("word")
affin_neg_words <- affin_neg %>% pull("word")
```


```{r}
length(affin_neg_words)
```


```{r}
affin_negative_tranlated_yoruba <- gl_translate(affin_neg_words, format = 'text', source = 'en', target = "yo", model = "nmt")
```

```{r}
length(affin_negative_tranlated_yoruba)
head(affin_negative_tranlated_yoruba)
```


```{r}
affin_positive_tranlated_yoruba <- gl_translate(affin_pos_words, format = 'text', source = 'en', target = "yo", model = "nmt")
```



```{r}
write.csv(affin_positive_tranlated_yoruba, "~/Documents/R Directory/HausaLex/affin_positive_tranlated_yoruba.csv")
write.csv(affin_negative_tranlated_yoruba, "~/Documents/R Directory/HausaLex/affin_negative_tranlated_yoruba.csv")

```




```{r}
affin_pos_words <-  affin_pos %>% filter("word")
affin_neg_words <- affin_neg %>% filter("word")
```


```{r}
join_affin <- full_join(affin_translated, affin_original, by = "word")
```


```{r}
affin_positive_tranlated_yoruba <- read_csv("affin_positive_tranlated_yoruba.csv")
```




```{r}
#head(affin_negative_tranlated_yoruba)
head(affin_positive_tranlated_yoruba) 
#affin_positive_tranlated_yoruba <- affin_positive_tranlated_yoruba %>% select(-X1)
```


Translating both affin translated negative and positive
```{r}


affin_positive_tranlated_yoruba <- affin_positive_tranlated_yoruba %>% rename( word = text )
#affin_negative_tranlated_yoruba <- affin_negative_tranlated_yoruba %>% rename( word = text )

#ead(affin_positive_tranlated)

#heaffin_positive_tranlated)
#head(affin_negative_tranlated)

#affin_pos
#affin_neg
```

merge
```{r}
affin_positive_yoruba_merged <- full_join(affin_pos, affin_positive_tranlated_yoruba, by = "word" ) 
affin_negative_yoruba_merged <- full_join(affin_neg, affin_negative_tranlated_yoruba, by = "word" )


```

```{r}
head(affin_positive_yoruba_merged)
```
```{r}
head(affin_negative_yoruba_merged)

```
Re-arrange
```{r}

affin_positive_yoruba_merged <- affin_positive_yoruba_merged %>% relocate(translatedText, .after = word )
affin_negative__yoruba_merged <- affin_negative_yoruba_merged %>% relocate(translatedText, .after = word )

```

```{r}
head(affin_positive_yoruba_merged)
```

```{r}
write.csv(affin_positive_yoruba_merged, "~/Documents/R Directory/HausaLex/affin_positive_yoruba_merged.csv")
write.csv(affin_negative__yoruba_merged, "~/Documents/R Directory/HausaLex/affin_negative__yoruba_mergedcsv")
```



```{r}
library(reticulate)
```

```{r}
conda_list()
```

```{r}
use_condaenv("r-reticulate")
```

```{r}
py_config()
```
```{r}
conda_install("r-reticulate", "nltk")
```


```{r}
nltk <- import("nltk")
```


```{python}
from nltk.corpus import sentiwordnet as swn

```


```{r}
library(lexicon)

sentiword <- data("hash_sentiment_sentiword")
p <- data(hash_sentiment_nrc)

```

```{r}

library(lexicon)

data(hash_sentiment_sentiword)


```

```{r}
hash_sentiment_sentiword
```

```{r}

sentiword_polarity <- hash_sentiment_sentiword %>% mutate(polarity = ifelse( y >0, "positive", "negative")) %>% view()

```

#renaming x and y
```{r}
sentiword_polarity <- sentiword_polarity %>% 
  rename(words = x,
        values= y )
```

```{r}
head(sentiword_polarity)
```


pivot wider
```{r}

sentiword_words_only <- sentiword_polarity %>% pull(words)
head(sentiword_words_only)
```


# translating senti_words
```{r}
sentiword_words_tranlated_yoruba <- gl_translate(sentiword_words_only, format = 'text', source = 'en', target = "yo", model = "nmt")
```


```{r}
sentiword_words_tranlated_yoruba <- sentiword_words_tranlated_yoruba %>% 
  rename(words = text)

nrow(sentiword_words_tranlated_yoruba)
```

```{r}
nrow(sentiword_polarity)
```

# joining the 
```{r}
sentiword_translation <- full_join(sentiword_words_tranlated_yoruba, sentiword_polarity , by = "words")
```


```{r}
head(sentiword_translation)
```

```{r}
sentiword_words_tranlated_yoruba <- sentiword_words_tranlated_yoruba %>% relocate(translatedText, .after = words )

```

```{r}
head(sentiword_words_tranlated_yoruba)
```


```{r}
write.csv(sentiword_words_tranlated_yoruba, "~/Documents/R Directory/HausaLex/sentiword_translation_yoruba.csv")

```

##-----------------------













<!-- In order to carryout this data driven project, we will follow `CRISP` methodoloy: -->

<!-- + Business Understanding -->
<!-- + Data Understanding -->
<!-- + Data Preparation -->
<!-- + Modeling -->
<!-- + Evaluation -->
<!-- + Deployment -->


## Translation of Bin Lui Sentiment Lexicon 

In this section, we translate Bin Liu sentiment lexicon. The lexicon contains, 6,786 words that are classified with sentiment orientation of either positive or negative. More detail about Bin Lui lexicon [here](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon)


```{r message=FALSE, warning=FALSE}
library(tidyverse)
```

Reading the translated lexicon from English to Hausa: 

```{r message=FALSE, warning=FALSE}
Bin_Pos <- as_tibble(read_csv(file = "bin_positive_tranlated.csv")) 
Bin_Pos
```

#TODO put how to explore data here

From the above, we have a total of `2,005` positive words from the lexicon.
Re-arranging :

```{r}

Bin_Pos <-  Bin_Pos %>%  
            relocate(text, .after = X1) %>% 
            rename(Seria_num = "X1")

Bin_Pos
```

After some few observations, I found out some lexicons are not translated to Hausa from English. Aagin, some words appeared to have repeated translation with `m` . Lets explore the non-translated and those with repated `m` as their translation:

```{r}
Bin_Pos <- Bin_Pos %>% 
        mutate(non_translated =  if_else(translatedText == text, Bin_Pos$text, " ")) %>% 
        mutate(repeated_m = if_else(translatedText == "m", "m", " "))
Bin_Pos
```

## How many words are not translated 

```{r}
sum(Bin_Pos$non_translated != " ")
```

## What are the words that are not translate?

```{r}

non_translated_words <- Bin_Pos %>% 
                  select(non_translated)  %>% 
                  filter( non_translated != " " )
          
non_translated_words
```


## How many words are translated as "m"

```{r}
sum(Bin_Pos$repeated_m != " ")
```

## What are the words translated as "m"

```{r}
translated_as_m <- Bin_Pos %>% 
                  select(repeated_m, translatedText, text) %>% 
                  filter(repeated_m == "m")
          
translated_as_m
```

##  This section explore Bin Lui negative lexicon and process Bin Lui


Reading the translated Bin Lui negative lexicon

```{r}
Bin_neg <- as_tibble(read_csv(file = "bin_negative_tranlated.csv"))

```


```{r}
Bin_neg
```


#TODO put how to explore data here

From the above, we have a total of `2,005` positive words from the lexicon.
Re-arranging :

```{r}

Bin_neg <-  Bin_neg %>%  
            relocate(text, .after = X1) %>% 
            rename(Seria_num = "X1")

Bin_neg
```


```{r}
Bin_neg <- Bin_neg %>% 
        mutate(non_translated =  if_else(translatedText == text, Bin_neg$text, " ")) %>% 
        mutate(repeated_m = if_else(translatedText == "m", "m", " "))
Bin_neg
```


## How many negative words are not translated 

```{r}
sum(Bin_neg$non_translated != " ")
```

## What are the words that are not translate?

```{r}

neg_non_translated <- Bin_neg %>% 
                  select(non_translated)  %>% 
                  filter(non_translated != " " )
          
neg_non_translated
```


## How many negative words are translated as "m"

```{r}
sum(Bin_neg$repeated_m != " ")
```

## What are the words translated as "m"

```{r}
neg_translated_as_m <- Bin_neg %>% 
                  select(repeated_m, translatedText, text) %>% 
                  filter(repeated_m == "m")
          
neg_translated_as_m
```

# Translated Affin Lexicon Processing and exploration

This section explore the translated `Affin lexicon`.


## Negative Affin Lexicon

```{r}
Affin_neg <- as_tibble(read_csv(file = "affin_negative_merged.csv"))

```


```{r}
head(Affin_neg, 10)
```

The translated Affin lexicon also contains `m` and non-translated words as in the `Bin Liu` lexicon. We did exactly as in the previous section.


```{r}
Affin_neg <- Affin_neg %>% 
        mutate(non_translated =  if_else(translatedText == word, Affin_neg$word, " ")) %>% 
        mutate(repeated_m = if_else(translatedText == "m", "m", " "))
Affin_neg
```



## How many negative words are not translated 

```{r}
sum(Affin_neg$non_translated != " ")
```

## What are the words that are not translate?

```{r}
Affin_neg_non_translated <- Affin_neg %>% 
                  select(non_translated)  %>% 
                  filter(non_translated != " " )
          
Affin_neg_non_translated
```

## Negative Affin Lexicon


### How many Affin positive words are not translated 



```{r}
Affin_pos <- as_tibble(read_csv(file = "affin_positive_merged.csv"))

```


```{r}
head(Affin_pos)
```

```{r}
Affin_pos <- Affin_pos %>% 
        mutate(non_translated =  if_else(translatedText == word, Affin_pos$word, " ")) %>% 
        mutate(repeated_m = if_else(translatedText == "m", "m", " "))
Affin_pos
```

## How many positive words that are not translated?


```{r}
sum(Affin_pos$non_translated != " ")
```

## What are the words that are not translate?

```{r}
pos_non_translated <- Affin_pos %>% 
                  select(non_translated)  %>% 
                  filter(non_translated != " " )
          
pos_non_translated
```

# Translated SentiWordNet Lexicon Processing and exploration

This section explore the translated `Affin lexicon`.


## Negative Affin Lexicon

```{r}
SentiWordNe <- as_tibble(read_csv(file = "sentiword_translation.csv"))

```

```{r}
SentiWordNe
```

Sentiwordnet is 20,093 in total.

```{r}
SentiWordNet <- SentiWordNe %>% 
        mutate(non_translated =  if_else(translatedText == words, SentiWordNe$words, " ")) %>% 
        mutate(repeated_m = if_else(translatedText == "m", "m", " ")) 
SentiWordNe
```

## How many positive words that are not translated?


```{r}
sum(SentiWordNet$non_translated != " ")
```

## What are the words that are not translate?

```{r}
SentNet_non_translated <- SentiWordNet %>% 
                  select(non_translated)  %>% 
                  filter(non_translated != " " )
          
SentNet_non_translated
```

#TODO
* Share paper in Github
* Do expirment with little data Twitter data
* Ten years of NRC emotion lexiocn: https://medium.com/@nlpscholar/ten-years-of-the-nrc-word-emotion-association-lexicon-eaa47a8dd03e
* expirement with R sentiment analysis tidyway

kya mu canjasu all kya ..k

## NRC dataset


```{r}
library(tidytext)
```

```{r}
#nrc < get_sentiments("nrc")
```

